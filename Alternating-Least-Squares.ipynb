{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternating Least Squares Implicit Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://jessesw.com/Rec-System/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import spsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_action = pd.read_csv('../input/제6회 L.POINT Big Data Competition-분석용데이터-01.온라인 행동 정보.csv', parse_dates=['sess_dt'])\n",
    "df_transaction = pd.read_csv('../input/제6회 L.POINT Big Data Competition-분석용데이터-02.거래 정보.csv', parse_dates=['de_dt'])\n",
    "# df_client_demo = pd.read_csv('../input/제6회 L.POINT Big Data Competition-분석용데이터-03.고객 Demographic 정보.csv')\n",
    "df_product = pd.read_csv('../input/제6회 L.POINT Big Data Competition-분석용데이터-04.상품분류 정보.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(599961, 12)\n"
     ]
    }
   ],
   "source": [
    "# convert df_product['pd_c'] datatype : int -> object\n",
    "df_product['pd_c'] = df_product['pd_c'].apply(lambda num: \"{:04n}\".format(num))\n",
    "\n",
    "# df_transaction and df_prodcct merge!\n",
    "df_transaction = pd.merge(df_transaction, df_product, how='left')\n",
    "print(df_transaction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(582283, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>trans_id</th>\n",
       "      <th>trans_seq</th>\n",
       "      <th>biz_unit</th>\n",
       "      <th>pd_c</th>\n",
       "      <th>de_dt</th>\n",
       "      <th>de_tm</th>\n",
       "      <th>buy_am</th>\n",
       "      <th>buy_ct</th>\n",
       "      <th>clac_nm1</th>\n",
       "      <th>clac_nm2</th>\n",
       "      <th>clac_nm3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>39423</td>\n",
       "      <td>105124</td>\n",
       "      <td>13</td>\n",
       "      <td>A03</td>\n",
       "      <td>0565</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>17:26</td>\n",
       "      <td>2990</td>\n",
       "      <td>1</td>\n",
       "      <td>Fruits</td>\n",
       "      <td>Imported Fruits</td>\n",
       "      <td>Bananas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>21279</td>\n",
       "      <td>104907</td>\n",
       "      <td>1</td>\n",
       "      <td>A03</td>\n",
       "      <td>0565</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>10:27</td>\n",
       "      <td>2990</td>\n",
       "      <td>1</td>\n",
       "      <td>Fruits</td>\n",
       "      <td>Imported Fruits</td>\n",
       "      <td>Bananas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>48969</td>\n",
       "      <td>104882</td>\n",
       "      <td>5</td>\n",
       "      <td>A03</td>\n",
       "      <td>0572</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>10:05</td>\n",
       "      <td>7490</td>\n",
       "      <td>1</td>\n",
       "      <td>Fruits</td>\n",
       "      <td>Imported Fruits</td>\n",
       "      <td>Kiwi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>30533</td>\n",
       "      <td>103245</td>\n",
       "      <td>5</td>\n",
       "      <td>A03</td>\n",
       "      <td>0670</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>14:36</td>\n",
       "      <td>49800</td>\n",
       "      <td>1</td>\n",
       "      <td>Grains</td>\n",
       "      <td>Rice</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>64346</td>\n",
       "      <td>104317</td>\n",
       "      <td>1</td>\n",
       "      <td>A03</td>\n",
       "      <td>0543</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>22:34</td>\n",
       "      <td>26900</td>\n",
       "      <td>1</td>\n",
       "      <td>Fruits</td>\n",
       "      <td>Domestic Fruits</td>\n",
       "      <td>Pears</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clnt_id  trans_id  trans_seq biz_unit  pd_c      de_dt  de_tm  buy_am  \\\n",
       "4    39423    105124         13      A03  0565 2019-09-20  17:26    2990   \n",
       "5    21279    104907          1      A03  0565 2019-09-20  10:27    2990   \n",
       "6    48969    104882          5      A03  0572 2019-09-20  10:05    7490   \n",
       "7    30533    103245          5      A03  0670 2019-09-20  14:36   49800   \n",
       "8    64346    104317          1      A03  0543 2019-09-20  22:34   26900   \n",
       "\n",
       "   buy_ct clac_nm1         clac_nm2 clac_nm3  \n",
       "4       1   Fruits  Imported Fruits  Bananas  \n",
       "5       1   Fruits  Imported Fruits  Bananas  \n",
       "6       1   Fruits  Imported Fruits     Kiwi  \n",
       "7       1   Grains             Rice     Rice  \n",
       "8       1   Fruits  Domestic Fruits    Pears  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd_c가 unknown은 drop\n",
    "df_transaction.dropna(axis=0, inplace=True)\n",
    "print(df_transaction.shape)\n",
    "df_transaction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pd_c</th>\n",
       "      <th>clac_nm1</th>\n",
       "      <th>clac_nm2</th>\n",
       "      <th>clac_nm3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0001</td>\n",
       "      <td>Automotive Products</td>\n",
       "      <td>Automotive Replacement Repair / Maintanance Kits</td>\n",
       "      <td>Automobile Oil / Additives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0002</td>\n",
       "      <td>Automotive Products</td>\n",
       "      <td>Automotive Replacement Repair / Maintanance Kits</td>\n",
       "      <td>Car Lights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0003</td>\n",
       "      <td>Automotive Products</td>\n",
       "      <td>Automotive Replacement Repair / Maintanance Kits</td>\n",
       "      <td>Car Paint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0004</td>\n",
       "      <td>Automotive Products</td>\n",
       "      <td>Automotive Replacement Repair / Maintanance Kits</td>\n",
       "      <td>Filters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0005</td>\n",
       "      <td>Automotive Products</td>\n",
       "      <td>Automotive Replacement Repair / Maintanance Kits</td>\n",
       "      <td>Wiper Blades</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pd_c             clac_nm1  \\\n",
       "0  0001  Automotive Products   \n",
       "1  0002  Automotive Products   \n",
       "2  0003  Automotive Products   \n",
       "3  0004  Automotive Products   \n",
       "4  0005  Automotive Products   \n",
       "\n",
       "                                           clac_nm2  \\\n",
       "0  Automotive Replacement Repair / Maintanance Kits   \n",
       "1  Automotive Replacement Repair / Maintanance Kits   \n",
       "2  Automotive Replacement Repair / Maintanance Kits   \n",
       "3  Automotive Replacement Repair / Maintanance Kits   \n",
       "4  Automotive Replacement Repair / Maintanance Kits   \n",
       "\n",
       "                     clac_nm3  \n",
       "0  Automobile Oil / Additives  \n",
       "1                  Car Lights  \n",
       "2                   Car Paint  \n",
       "3                     Filters  \n",
       "4                Wiper Blades  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(327638, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>pd_c</th>\n",
       "      <th>buy_ct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0092</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0351</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1395</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clnt_id  pd_c  buy_ct\n",
       "0        2  0092      26\n",
       "1        2  0151       1\n",
       "2        2  0186       1\n",
       "3        2  0189       1\n",
       "4        2  0351       1\n",
       "5        2  0857       1\n",
       "6        2  1015       1\n",
       "7        2  1395       4\n",
       "8        9  0114       1\n",
       "9        9  0188       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_transaction[['clnt_id', 'pd_c', 'buy_ct']]\n",
    "grouped_df =df.groupby(['clnt_id', 'pd_c']).sum().reset_index()\n",
    "\n",
    "# Replace a sum of zero purchases with a one to indicate purchased\n",
    "grouped_df.buy_ct.loc[grouped_df.buy_ct == 0] = 1 \n",
    "\n",
    "print(grouped_df.shape)\n",
    "grouped_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead of representing an explicit rating, the purchase quantity can represent a \"confidence\" in terms of how strong the interaction was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(327638, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>pd_c</th>\n",
       "      <th>buy_ct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0092</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0351</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clnt_id  pd_c  buy_ct\n",
       "0        2  0092      26\n",
       "1        2  0151       1\n",
       "2        2  0186       1\n",
       "3        2  0189       1\n",
       "4        2  0351       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only get customers where purchase totals were positive\n",
    "grouped_purchased = grouped_df.query('buy_ct > 0')\n",
    "print(grouped_purchased.shape)\n",
    "grouped_purchased.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11270 1665 327638\n"
     ]
    }
   ],
   "source": [
    "customers = list(np.sort(grouped_purchased.clnt_id.unique()))\n",
    "products = list(grouped_purchased.pd_c.unique())\n",
    "quantity = list(grouped_purchased.buy_ct)\n",
    "print(len(customers), len(products), len(quantity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = grouped_purchased.clnt_id.astype('category', categoried = customers).cat.codes.astype(int)\n",
    "cols = grouped_purchased.pd_c.astype('category', categoried = products).cat.codes.astype(int)\n",
    "\n",
    "# Create a sparse matrix for our users and mcats containing number of purchases\n",
    "purchases_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(customers), len(products)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11270x1665 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 327638 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchases_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.25395226637463"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 98.3% of the interaction matrix is sparse.\n",
    "matrix_size = purchases_sparse.shape[0] * purchases_sparse.shape[1]\n",
    "# Number of items interacted with\n",
    "num_purchases = len(purchases_sparse.nonzero()[0])\n",
    "sparsity = 100 * (1 - (num_purchases/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Traning and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return our training set, a test set that has been binarized to 0/1 for purchased/not purchased, and a list of which users had at least one item masked. We will test the performance of the recommender system on these users only. I am masking 20% of the user/item interactions for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(ratings, pct_test=0.2):\n",
    "    '''\n",
    "    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
    "    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n",
    "    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n",
    "    \n",
    "    parameters: \n",
    "    \n",
    "    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
    "    copy of the original set. This is in the form of a sparse csr_matrix. \n",
    "    \n",
    "    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n",
    "    training set for later comparison to the test set, which contains all of the original ratings. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    training_set - The altered version of the original data with a certain percentage of the user-item pairs \n",
    "    that originally had interaction set back to zero.\n",
    "    \n",
    "    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
    "    compares with the actual interactions.\n",
    "    \n",
    "    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
    "    This will be necessary later when evaluating the performance via AUC.\n",
    "    '''\n",
    "    # Make a copy of the original set to be the test set. \n",
    "    test_set = ratings.copy()\n",
    "    # Store the test set as a binary preference matrix\n",
    "    test_set[test_set != 0] = 1\n",
    "    # Make a copy of the original data we can alter as our training set.\n",
    "    training_set = ratings.copy()\n",
    "    # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_inds = training_set.nonzero() \n",
    "    # Zip these pairs together of user,item index into list\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1]))\n",
    "    # Set the random seed to zero for reproducibility\n",
    "    random.seed(0)\n",
    "    # Round the number of samples needed to the nearest integer\n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs)))\n",
    "    # Sample a random number of user-item pairs without replacement\n",
    "    samples = random.sample(nonzero_pairs, num_samples)\n",
    "    # Get the user row indices\n",
    "    user_inds = [index[0] for index in samples]\n",
    "    # Get the item column indices\n",
    "    item_inds = [index[1] for index in samples]\n",
    "    # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set[user_inds, item_inds] = 0 \n",
    "    # Get rid of zeros in sparse array storage after update to save space\n",
    "    training_set.eliminate_zeros()\n",
    "    \n",
    "    # Output the unique list of user rows that were altered \n",
    "    return training_set, test_set, list(set(user_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_train, product_test, product_users_altered = make_train(purchases_sparse, pct_test=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11270, 1665), (11270, 1665))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_train.shape, product_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_weighted_ALS(training_set, lambda_val=0.1, alpha=40, iterations=10, rank_size=20, seed=0):\n",
    "    '''\n",
    "    Implicit weighted ALS taken from Hu, Koren, and Volinsky 2008. Designed for alternating least squares and implicit\n",
    "    feedback based collaborative filtering. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - Our matrix of ratings with shape m x n, where m is the number of users and n is the number of items.\n",
    "    Should be a sparse csr matrix to save space. \n",
    "    \n",
    "    lambda_val - Used for regularization during alternating least squares. Increasing this value may increase bias\n",
    "    but decrease variance. Default is 0.1. \n",
    "    \n",
    "    alpha - The parameter associated with the confidence matrix discussed in the paper, where Cui = 1 + alpha*Rui. \n",
    "    The paper found a default of 40 most effective. Decreasing this will decrease the variability in confidence between\n",
    "    various ratings.\n",
    "    \n",
    "    iterations - The number of times to alternate between both user feature vector and item feature vector in\n",
    "    alternating least squares. More iterations will allow better convergence at the cost of increased computation. \n",
    "    The authors found 10 iterations was sufficient, but more may be required to converge. \n",
    "    \n",
    "    rank_size - The number of latent features in the user/item feature vectors. The paper recommends varying this \n",
    "    between 20-200. Increasing the number of features may overfit but could reduce bias. \n",
    "    \n",
    "    seed - Set the seed for reproducible results\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The feature vectors for users and items. The dot product of these feature vectors should give you the expected \n",
    "    \"rating\" at each point in your original matrix. \n",
    "    '''\n",
    "    \n",
    "    # first set up our confidence matrix\n",
    "    \n",
    "    # To allow the matrix to stay sparse, I will add one later when each row is taken and converted to dence\n",
    "    conf = (alpha*training_set) \n",
    "    num_user = conf.shape[0]\n",
    "    # Get the size of our original ratings matrix, m X n \n",
    "    num_item = conf.shape[1]\n",
    "    \n",
    "    # initialize our X/Y feature vectors randomly with a set seed\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    \n",
    "    # Random numbers in a m x rank shape\n",
    "    X = sparse.csr_matrix(rstate.normal(size = (num_user, rank_size)))\n",
    "    # Normally this would be rank x n but we can transpose at the end. Makes calculation more simple.\n",
    "    Y = sparse.csr_matrix(rstate.normal(size = (num_item, rank_size)))\n",
    "    \n",
    "    X_eye = sparse.eye(num_user)\n",
    "    Y_eye = sparse.eye(num_item)\n",
    "    # Our regularization term lambda * I\n",
    "    lambda_eye = lambda_val * sparse.eye(rank_size)\n",
    "    \n",
    "    # We can compute this before iteration starts.\n",
    "    \n",
    "    # Begin iterations\n",
    "    \n",
    "    # Iterate back and forth between solving X given fixed Y and vice verse\n",
    "    for iter_step in range(iterations): \n",
    "        # Compute yTy and xTx at begining of each iteration to save computing time\n",
    "        yTy = Y.T.dot(Y)\n",
    "        xTx = X.T.dot(X)\n",
    "        \n",
    "        # Being iteration to solve for X based on fixed Y \n",
    "        for u in range(num_user):\n",
    "            # Grab user row from confidence matrix and convert to dence\n",
    "            conf_samp = conf[u, :].toarray()\n",
    "            pref = conf_samp.copy()\n",
    "            pref[pref != 0] = 1  # Create binarized preference vector \n",
    "            CuI = sparse.diags(conf_samp, [0]) # Get Cu - I term, don't need to subtract 1 since we never added it \n",
    "            yTCuIY = Y.T.dot(CuI).dot(Y) # This is the yT(Cu-I)Y term\n",
    "            yTCupu = Y.T.dot(CuI + Y_eye).dot(pref.T) # This is the yTCuPu term, where we add the eye back in Cu - I + I = Cu\n",
    "            X[u] = spsolve(yTy + yTCuIY + lambda_eye, yTCupu)\n",
    "            # Solve for Xu = ((yTy + yT(Cu-I)Y + lambda*I)^-1)yTCuPu, equation 4 from the paper\n",
    "            \n",
    "        # Begin iteration to solve for Y based on fixed X\n",
    "        for i in range(num_item):\n",
    "            conf_samp = conf[:, i].T.toarray() # Transpose to get it in row format and convert to dense\n",
    "            pref = conf_samp.copy()\n",
    "            pref[pref != 0] = 1 # Create binarized preference vector\n",
    "            CiI = sparse.diags(conf_samp, [0]) # Get Ci-I term, don't need to subtract 1 since we never added it\n",
    "            xTCiIX = X.T.dot(CiI).dot(X) # This is the xT(Cu-I)X term\n",
    "            xTCiPi = X.T.dot(CiI + X_eye).dot(pref.T) # this is the xTCiPi term\n",
    "            Y[i] = spsolve(xTx + xTCiIX + lambda_eye, xTCiPi)\n",
    "            # Solve for Yi = ((xTx + xT(Cu-I)X + lambda*I)^-1)xTCiPi, equtation 5 from paper\n",
    "            \n",
    "        # End iterations\n",
    "        # Transpose at the end to make up for not being transposed at the begining.\n",
    "        # Y needs to be rank x n. Keep these as separate matrices for scale reasons \n",
    "        return X, Y.T  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vecs, item_vecs = implicit_weighted_ALS(product_train, lambda_val=0.1, alpha=15, iterations=10, rank_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.07579489e-06, -2.25386050e-05, -7.62959485e-05, -1.90207270e-05,\n",
       "        3.38033606e-05, -7.90647854e-04, -1.20627512e-04, -6.01797842e-05,\n",
       "       -1.42114880e-05, -5.07013351e-05])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vecs[0, :].dot(item_vecs).toarray()[0, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(predictions, test):\n",
    "    '''\n",
    "    This simple function will output the area under the curve using sklearn's metrics. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    - predictions: your prediction output\n",
    "    \n",
    "    - test: the actual target result you are comparing to\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    - AUC (area under the Receiver Operating Characterisic curve)\n",
    "    '''\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_auc(training_set, altered_users, predictions, test_set):\n",
    "    '''\n",
    "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - The training set resulting from make_train, where a certain percentage of the original\n",
    "    user/item interactions are reset to zero to hide them from the model \n",
    "    \n",
    "    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n",
    "    These should be stored in a list, with user vectors as item zero and item vectors as item one. \n",
    "    \n",
    "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n",
    "    \n",
    "    test_set - The test set constucted earlier from make_train function\n",
    "    \n",
    "    \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n",
    "    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
    "    '''\n",
    "    # An empty list to store the AUC for each user that had an item removed from the trainig set\n",
    "    store_auc = [] \n",
    "    # To store popular AUC scores\n",
    "    popularity_auc = []\n",
    "    # Get sum of item iterations to find most popular \n",
    "    pop_items = np.array(test_set.sum(axis=0)).reshape(-1)\n",
    "    item_vecs = predictions[1]\n",
    "    # Iterate through each user that had an item altered \n",
    "    for user in altered_users:\n",
    "        training_row = training_set[user,:].toarray().reshape(-1)# Get sum of item iteractions to find most popular\n",
    "        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "        \n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        user_vec = predictions[0][user,:]\n",
    "        pred = user_vec.dot(item_vecs.T).toarray()[0, zero_inds].reshape(-1)\n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[user,:].toarray()[0, zero_inds].reshape(-1)\n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training\n",
    "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "        \n",
    "    # End users iteration\n",
    "    \n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))\n",
    "    # Return the mean AUC rounded to there decimal places for both test and popularity benchmark\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.891)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC for our recommender system\n",
    "calc_mean_auc(product_train, product_users_altered, [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our recommender system had a mean AUC of 0.80, while the popular item benchmark had a higher AUC of 0.89. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Recommendation Example\n",
    "Let's examine the recommendations given to a particular user and decide subjectively if they make any sense.\n",
    "\n",
    "we need to find a way of retrieving the items already purchased by a user in the training set. Initially, we will create an array of our customers and items we made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of customer IDs from the ratings matrix\n",
    "customers_arr = np.array(customers)\n",
    "# Array of product IDs from the ratings matrix\n",
    "products_arr = np.array(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_purchased(customer_id, df_transaction, df_product):\n",
    "    '''\n",
    "    This just tells me which items have been already purchased by a specific user in the training set. \n",
    "    \n",
    "    parameters: \n",
    "    \n",
    "    customer_id - Input the customer's id number that you want to see prior purchases of at least once\n",
    "    \n",
    "    mf_train - The initial ratings training set used (without weights applied)\n",
    "    \n",
    "    customers_list - The array of customers used in the ratings matrix\n",
    "    \n",
    "    products_list - The array of products used in the ratings matrix\n",
    "    \n",
    "    item_lookup - A simple pandas dataframe of the unique product ID/product descriptions available\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    A list of item IDs and item descriptions for a particular customer that were already purchased in the training set\n",
    "    '''\n",
    "    # Returns the index row of our customer id\n",
    "#     cust_ind = np.where(customers_list == customer_id)[0][0]\n",
    "    \n",
    "    # Get column indics of purchased items\n",
    "#     purchased_ind = mf_train[cust_ind,:].nonzero()[1]\n",
    "    \n",
    "    # Get the stock codes for our purchased items\n",
    "#     prod_codes = products_list[purchased_ind]\n",
    "#     return item_lookup.loc[item_lookup.pd_c.isin(prod_codes)]\n",
    "    purchase_items = df_transaction.loc[df_transaction['clnt_id'] == customer_id].pd_c.to_list()\n",
    "    return df_product[df_product.pd_c.isin(purchase_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    2,     9,    12, ..., 72410, 72423, 72424])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pd_c</th>\n",
       "      <th>clac_nm1</th>\n",
       "      <th>clac_nm2</th>\n",
       "      <th>clac_nm3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0098</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Fruit and Vegetable Drinks</td>\n",
       "      <td>Mixed Fruit / Vegetable Drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0114</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Water</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0186</td>\n",
       "      <td>Chilled Foods</td>\n",
       "      <td>Fish Cakes and Crab Sticks</td>\n",
       "      <td>Crab Sticks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0188</td>\n",
       "      <td>Chilled Foods</td>\n",
       "      <td>Fish Cakes and Crab Sticks</td>\n",
       "      <td>Fish Cakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0189</td>\n",
       "      <td>Chilled Foods</td>\n",
       "      <td>Fish Cakes and Crab Sticks</td>\n",
       "      <td>Fried Tofu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0192</td>\n",
       "      <td>Chilled Foods</td>\n",
       "      <td>Ham and Sausages</td>\n",
       "      <td>Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0198</td>\n",
       "      <td>Chilled Foods</td>\n",
       "      <td>Packaged Side Dishes</td>\n",
       "      <td>Pickled Radishes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0236</td>\n",
       "      <td>Coffee / Tea</td>\n",
       "      <td>Brewed Coffee</td>\n",
       "      <td>Tea Bags and Ground Coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>0336</td>\n",
       "      <td>Cosmetics / Beauty Care</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Essence / Serums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347</td>\n",
       "      <td>0348</td>\n",
       "      <td>Dairy Products</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Functional Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>0350</td>\n",
       "      <td>Dairy Products</td>\n",
       "      <td>Processed Dairy Products</td>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353</td>\n",
       "      <td>0354</td>\n",
       "      <td>Dairy Products</td>\n",
       "      <td>Yogurt</td>\n",
       "      <td>Spoon Type Yogurts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>0565</td>\n",
       "      <td>Fruits</td>\n",
       "      <td>Imported Fruits</td>\n",
       "      <td>Bananas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>669</td>\n",
       "      <td>0670</td>\n",
       "      <td>Grains</td>\n",
       "      <td>Rice</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>719</td>\n",
       "      <td>0720</td>\n",
       "      <td>Health Foods</td>\n",
       "      <td>Nutritional Supplements</td>\n",
       "      <td>Multi Nutritional Supplements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>841</td>\n",
       "      <td>0842</td>\n",
       "      <td>Kids' Clothing</td>\n",
       "      <td>Preschoolers' Lower Bodywear / Bottoms</td>\n",
       "      <td>Infant / Toddlers' Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>868</td>\n",
       "      <td>0869</td>\n",
       "      <td>Kitchenware</td>\n",
       "      <td>Kitchen Cookware</td>\n",
       "      <td>Kitchen Cookware Sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>0893</td>\n",
       "      <td>Liquors / Alcoholic Beverages</td>\n",
       "      <td>Beer</td>\n",
       "      <td>Domestic Beer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>963</td>\n",
       "      <td>0964</td>\n",
       "      <td>Meats</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Chicken Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1183</td>\n",
       "      <td>1184</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>Biscuits</td>\n",
       "      <td>Crackers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1199</td>\n",
       "      <td>1200</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>Korean Traditional Snacks</td>\n",
       "      <td>Other Korean Traditional Snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1209</td>\n",
       "      <td>1210</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>Snacks</td>\n",
       "      <td>Corn Snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1212</td>\n",
       "      <td>1213</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>Snacks</td>\n",
       "      <td>General Snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1214</td>\n",
       "      <td>1215</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>Snacks</td>\n",
       "      <td>Potato Snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1215</td>\n",
       "      <td>1216</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>Snacks</td>\n",
       "      <td>Rice Snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1231</td>\n",
       "      <td>1232</td>\n",
       "      <td>Spices / Seasonings</td>\n",
       "      <td>Mature Sauces</td>\n",
       "      <td>Doenjang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1232</td>\n",
       "      <td>1233</td>\n",
       "      <td>Spices / Seasonings</td>\n",
       "      <td>Mature Sauces</td>\n",
       "      <td>Gochujang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1382</td>\n",
       "      <td>1383</td>\n",
       "      <td>Substitute Foods</td>\n",
       "      <td>Cereals</td>\n",
       "      <td>General Cereals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1586</td>\n",
       "      <td>1587</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>Leaf Vegetables</td>\n",
       "      <td>Sesame Leaves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1614</td>\n",
       "      <td>1615</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>Tofu / Bean Sprouts</td>\n",
       "      <td>Silken Tofu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1665</td>\n",
       "      <td>1666</td>\n",
       "      <td>Women's Clothing</td>\n",
       "      <td>Women's Upper Bodywear / Tops</td>\n",
       "      <td>Women's T-shirts / Tops</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pd_c                       clac_nm1  \\\n",
       "97    0098                      Beverages   \n",
       "113   0114                      Beverages   \n",
       "185   0186                  Chilled Foods   \n",
       "187   0188                  Chilled Foods   \n",
       "188   0189                  Chilled Foods   \n",
       "191   0192                  Chilled Foods   \n",
       "197   0198                  Chilled Foods   \n",
       "235   0236                   Coffee / Tea   \n",
       "335   0336        Cosmetics / Beauty Care   \n",
       "347   0348                 Dairy Products   \n",
       "349   0350                 Dairy Products   \n",
       "353   0354                 Dairy Products   \n",
       "564   0565                         Fruits   \n",
       "669   0670                         Grains   \n",
       "719   0720                   Health Foods   \n",
       "841   0842                 Kids' Clothing   \n",
       "868   0869                    Kitchenware   \n",
       "892   0893  Liquors / Alcoholic Beverages   \n",
       "963   0964                          Meats   \n",
       "1183  1184                    Snack Foods   \n",
       "1199  1200                    Snack Foods   \n",
       "1209  1210                    Snack Foods   \n",
       "1212  1213                    Snack Foods   \n",
       "1214  1215                    Snack Foods   \n",
       "1215  1216                    Snack Foods   \n",
       "1231  1232            Spices / Seasonings   \n",
       "1232  1233            Spices / Seasonings   \n",
       "1382  1383               Substitute Foods   \n",
       "1586  1587                     Vegetables   \n",
       "1614  1615                     Vegetables   \n",
       "1665  1666               Women's Clothing   \n",
       "\n",
       "                                    clac_nm2                         clac_nm3  \n",
       "97                Fruit and Vegetable Drinks   Mixed Fruit / Vegetable Drinks  \n",
       "113                                    Water                            Water  \n",
       "185               Fish Cakes and Crab Sticks                      Crab Sticks  \n",
       "187               Fish Cakes and Crab Sticks                       Fish Cakes  \n",
       "188               Fish Cakes and Crab Sticks                       Fried Tofu  \n",
       "191                         Ham and Sausages                              Ham  \n",
       "197                     Packaged Side Dishes                 Pickled Radishes  \n",
       "235                            Brewed Coffee       Tea Bags and Ground Coffee  \n",
       "335                                Skin Care                 Essence / Serums  \n",
       "347                                     Milk                  Functional Milk  \n",
       "349                 Processed Dairy Products                           Cheese  \n",
       "353                                   Yogurt               Spoon Type Yogurts  \n",
       "564                          Imported Fruits                          Bananas  \n",
       "669                                     Rice                             Rice  \n",
       "719                  Nutritional Supplements    Multi Nutritional Supplements  \n",
       "841   Preschoolers' Lower Bodywear / Bottoms         Infant / Toddlers' Pants  \n",
       "868                         Kitchen Cookware            Kitchen Cookware Sets  \n",
       "892                                     Beer                    Domestic Beer  \n",
       "963                                     Eggs                     Chicken Eggs  \n",
       "1183                                Biscuits                         Crackers  \n",
       "1199               Korean Traditional Snacks  Other Korean Traditional Snacks  \n",
       "1209                                  Snacks                      Corn Snacks  \n",
       "1212                                  Snacks                   General Snacks  \n",
       "1214                                  Snacks                    Potato Snacks  \n",
       "1215                                  Snacks                      Rice Snacks  \n",
       "1231                           Mature Sauces                         Doenjang  \n",
       "1232                           Mature Sauces                        Gochujang  \n",
       "1382                                 Cereals                  General Cereals  \n",
       "1586                         Leaf Vegetables                    Sesame Leaves  \n",
       "1614                     Tofu / Bean Sprouts                      Silken Tofu  \n",
       "1665           Women's Upper Bodywear / Tops          Women's T-shirts / Tops  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_items_purchased(72410, df_transaction, df_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
