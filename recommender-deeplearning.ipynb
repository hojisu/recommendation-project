{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalized Ranking for Recommender Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon, np, npx\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Personalized Ranking Loss and its Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved in the d2l package for later use\n",
    "class BPRLoss(gluon.loss.Loss):\n",
    "    def __init__(self, weight=None, batch_axis=0, **kwargs):\n",
    "        super(BPRLoss, self).__init__(weight=None, batch_axis=0, **kwargs)\n",
    "\n",
    "    def forward(self, positive, negative):\n",
    "        distances = positive - negative\n",
    "        loss = - np.sum(np.log(npx.sigmoid(distances)), 0, keepdims=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinge Loss and its Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved in the d2l package for later use\n",
    "class HingeLossbRec(gluon.loss.Loss):\n",
    "    def __init__(self, weight=None, batch_axis=0, **kwargs):\n",
    "        super(HingeLossbRec, self).__init__(weight=None, batch_axis=0,\n",
    "                                            **kwargs)\n",
    "\n",
    "    def forward(self, positive, negative, margin=1):\n",
    "        distances = positive - negative\n",
    "        loss = np.sum(np.maximum(- distances + margin, 0))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Collaborative Filtering for Personalized Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing the neural collaborative filtering(NCF) framework for recommendation with implicit feedback. Actions such as Clicks, buys, and watches are common implicit feedback which are easy to collect and indicative of users' preferences.\n",
    "\n",
    "NeuMF(neural matrix factorization)\n",
    "- aims to address the personalized ranking task with implicit feedback\n",
    "- This model leverages the flexibility and non-linearity of neural networks to replace dot products of matrix factorization, aiming at enhancing the model expressiveness.\n",
    "- In specific, this model is structured with two subnetworks including generalized matrix factorization (GMF) and multilayer perceptron (MLP) and models the interactions from two pathways instead of simple inner products. The outputs of these two networks are concatenated for the final prediction scores calculation. \n",
    "- Unlike the rating prediction task in AutoRec, this model generates a ranked recommendation list to each user based on the implicit feedback. We will use the personalized ranking loss introduced in the last section to train this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NeuMF-model](../image/NeuMF-model.png)\n",
    "<center>llustration of the NeuMF model<\\center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2l\n",
    "from mxnet import autograd, gluon, np, npx\n",
    "from mxnet.gluon import nn\n",
    "import mxnet as mx\n",
    "import random\n",
    "import sys\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Block):\n",
    "    def __init__(self, num_factors, num_users, num_items, mlp_layers, **kwargs):\n",
    "        super(NeuMF, self).__init__(**kwargs)\n",
    "        self.P = nn.Embedding(num_users, num_factors)\n",
    "        self.Q = nn.Embedding(num_items, num_factors)\n",
    "        self.U = nn.Embedding(num_users, num_factors)\n",
    "        self.V = nn.Embedding(num_items, num_factors)\n",
    "        self.mlp = nn.Sequential()  # The MLP layers\n",
    "        for i in mlp_layers:\n",
    "            self.mlp.add(gluon.nn.Dense(i, activation='relu', use_bias=True))\n",
    "    \n",
    "    def forward(self, user_id, item_id):\n",
    "        p_mf = self.P(user_id)\n",
    "        q_mf = self.Q(item_id)\n",
    "        gmf = p_mf * q_mf\n",
    "        p_mlp = self.U(user_id)\n",
    "        q_mlp = self.V(item_id)\n",
    "        mlp = self.mlp(np.concatenate([p_mlp, q_mlp], axis=1))\n",
    "        con_res = np.concatenate([gmf, mlp], axis=1)\n",
    "        return np.sum(con_res, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Dataset with Negative Sampling\n",
    "The following function takes users identity and candidate items as input, and samples negative items randomly for each user from the candidate set of that user. During the training stage, the model ensures that the items that a user likes to be ranked higher than items she dislikes or has not interacted with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRDataset(gluon.data.Dataset):\n",
    "    def __init__(self, users, items, candidates, num_items):\n",
    "        self.users = users\n",
    "        self.items = items\n",
    "        self.cand = candidates\n",
    "        self.all = set([i for i in range(num_items)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        neg_items = list(self.all - set(self.cand[int(self.users[idx])]))\n",
    "        indices = random.randint(0, len(neg_items) - 1)\n",
    "        return self.users[idx], self.items[idx], neg_items[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved in the d2l package for later use\n",
    "def hit_and_auc(rankedlist, test_matrix, k):\n",
    "    hits_k = [(idx, val) for idx, val in enumerate(rankedlist[:k])\n",
    "              if val in set(test_matrix)]\n",
    "    hits_all = [(idx, val) for idx, val in enumerate(rankedlist)\n",
    "                if val in set(test_matrix)]\n",
    "    max = len(rankedlist) - 1\n",
    "    auc = 1.0 * (max - hits_all[0][0]) / max if len(hits_all) > 0 else 0\n",
    "    return len(hits_k), auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved in the d2l package for later use\n",
    "def evaluate_ranking(net, test_input, seq, candidates, num_users, num_items,\n",
    "                     ctx):\n",
    "    ranked_list, ranked_items, hit_rate, auc = {}, {}, [], []\n",
    "    all_items = set([i for i in range(num_users)])\n",
    "    for u in range(num_users):\n",
    "        neg_items = list(all_items - set(candidates[int(u)]))\n",
    "        user_ids, item_ids, x, scores = [], [], [], []\n",
    "        [item_ids.append(i) for i in neg_items]\n",
    "        [user_ids.append(u) for _ in neg_items]\n",
    "        x.extend([np.array(user_ids)])\n",
    "        if seq is not None:\n",
    "            x.append(seq[user_ids, :])\n",
    "        x.extend([np.array(item_ids)])\n",
    "        test_data_iter = gluon.data.DataLoader(gluon.data.ArrayDataset(*x),\n",
    "                                               shuffle=False,\n",
    "                                               last_batch=\"keep\",\n",
    "                                               batch_size=1024)\n",
    "        for index, values in enumerate(test_data_iter):\n",
    "            x = [gluon.utils.split_and_load(v, ctx, even_split=False)\n",
    "                 for v in values]\n",
    "            scores.extend([list(net(*t).asnumpy()) for t in zip(*x)])\n",
    "        scores = [item for sublist in scores for item in sublist]\n",
    "        item_scores = list(zip(item_ids, scores))\n",
    "        ranked_list[u] = sorted(item_scores, key=lambda t: t[1], reverse=True)\n",
    "        ranked_items[u] = [r[0] for r in ranked_list[u]]\n",
    "        temp = hit_and_auc(ranked_items[u], test_input[u], 50)\n",
    "        hit_rate.append(temp[0])\n",
    "        auc.append(temp[1])\n",
    "    return np.mean(np.array(hit_rate)), np.mean(np.array(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved in the d2l package for later use\n",
    "def train_ranking(net, train_iter, test_iter, loss, trainer, test_seq_iter,\n",
    "                  num_users, num_items, num_epochs, ctx_list, evaluator,\n",
    "                  candidates, eval_step=1):\n",
    "    timer, hit_rate, auc = d2l.Timer(), 0, 0\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],\n",
    "                            legend=['test hit rate', 'test AUC'])\n",
    "    for epoch in range(num_epochs):\n",
    "        metric, l = d2l.Accumulator(3), 0.\n",
    "        for i, values in enumerate(train_iter):\n",
    "            input_data = []\n",
    "            for v in values:\n",
    "                input_data.append(gluon.utils.split_and_load(v, ctx_list))\n",
    "            with autograd.record():\n",
    "                p_pos = [net(*t) for t in zip(*input_data[0:-1])]\n",
    "                p_neg = [net(*t) for t in zip(*input_data[0:-2],\n",
    "                                              input_data[-1])]\n",
    "                ls = [loss(p, n) for p, n in zip(p_pos, p_neg)]\n",
    "            [l.backward(retain_graph=False) for l in ls]\n",
    "            l += sum([l.asnumpy() for l in ls]).mean()/len(ctx_list)\n",
    "            trainer.step(values[0].shape[0])\n",
    "            metric.add(l, values[0].shape[0], values[0].size)\n",
    "            timer.stop()\n",
    "        with autograd.predict_mode():\n",
    "            if (epoch + 1) % eval_step == 0:\n",
    "                hit_rate, auc = evaluator(net, test_iter, test_seq_iter,\n",
    "                                          candidates, num_users, num_items,\n",
    "                                          ctx_list)\n",
    "                animator.add(epoch + 1, (hit_rate, auc))\n",
    "    print('train loss %.3f, test hit rate %.3f, test AUC %.3f'\n",
    "          % (metric[0] / metric[1], hit_rate, auc))\n",
    "    print('%.1f examples/sec on %s'\n",
    "          % (metric[2] * num_epochs / timer.sum(), ctx_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
